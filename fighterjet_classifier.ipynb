{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”„ Set this to True if you want to load a saved model otherwise False\n",
        "LOAD_SAVED_MODEL = False"
      ],
      "metadata": {
        "id": "KjJ-wdiTCeJ2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# ğŸ“¦ Setup\n",
        "# -----------------------------------------\n",
        "!pip install tensorflow --quiet\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import os\n",
        "\n",
        "print(\"âœ… TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeSlCePYygci",
        "outputId": "b4455a5f-3199-4315-ce25-047bdac6fa57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… TensorFlow version: 2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ“ Part 1 - Data Preprocessing**"
      ],
      "metadata": {
        "id": "2o4RFFbZzCWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# Part 1 - Simple Data Preprocessing\n",
        "# -----------------------------------------\n",
        "\n",
        "# Mount Google Drive (if using Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except:\n",
        "    print(\"Not running in Colab - skipping Google Drive mount\")\n",
        "\n",
        "# âœ… Settings\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# âœ… Load Dataset\n",
        "dataset_path = '/content/drive/MyDrive/dataset_balanced'\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.1,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# âœ… Get class names\n",
        "class_names = train_ds.class_names\n",
        "print(f\"âœ… Classes: {class_names}\")\n",
        "\n",
        "# âœ… Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.02),\n",
        "    layers.RandomZoom(0.02),\n",
        "])\n",
        "\n",
        "# âœ… Normalize images\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# âœ… Performance Boost\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.shuffle(1000).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# âœ… Compute class weights\n",
        "y_train = []\n",
        "for _, labels in train_ds.unbatch():\n",
        "    y_train.append(labels.numpy())\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_array))\n",
        "print(\"âœ… Class Weights:\", class_weights)\n",
        "\n",
        "# Display label distribution\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"âœ… Label Distribution:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYbOtr1yyxbz",
        "outputId": "4b280b48-0834-4a00-d7de-348dda609af9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Found 1800 files belonging to 4 classes.\n",
            "Using 1620 files for training.\n",
            "Found 1800 files belonging to 4 classes.\n",
            "Using 180 files for validation.\n",
            "âœ… Classes: ['AH64', 'B1', 'B2', 'E2']\n",
            "âœ… Class Weights: {0: np.float64(0.9975369458128078), 1: np.float64(1.0150375939849625), 2: np.float64(0.995085995085995), 3: np.float64(0.9926470588235294)}\n",
            "âœ… Label Distribution: {np.int32(0): np.int64(406), np.int32(1): np.int64(399), np.int32(2): np.int64(407), np.int32(3): np.int64(408)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ§ Part 2 - Building the CNN**"
      ],
      "metadata": {
        "id": "zddSuA_wzOEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# Part 2 - Simple & Effective CNN Architecture with Save/Load Feature\n",
        "# -----------------------------------------\n",
        "\n",
        "if LOAD_SAVED_MODEL and os.path.exists(model_path):\n",
        "    # âœ… Load the model from Google Drive\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    print(\"âœ… Loaded model from Google Drive â€” training skipped.\")\n",
        "else:\n",
        "    # âœ… Create a simple but effective CNN\n",
        "    def create_simple_effective_cnn(num_classes):\n",
        "        model = models.Sequential([\n",
        "\n",
        "\n",
        "            # Block 1\n",
        "            layers.Conv2D(32, (3, 3), padding='same', input_shape=(img_size[0], img_size[1], 3)),\n",
        "            data_augmentation,\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.1),\n",
        "\n",
        "            # Block 2\n",
        "            layers.Conv2D(64, (3, 3), padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.1),\n",
        "\n",
        "            # Block 3\n",
        "            layers.Conv2D(128, (3, 3), padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.1),\n",
        "\n",
        "            # Block 4\n",
        "            layers.Conv2D(256, (3, 3), padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.1),\n",
        "\n",
        "            # Dense Layers\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.Dropout(0.2),\n",
        "\n",
        "            layers.Dense(256, kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Activation('relu'),\n",
        "            layers.Dropout(0.2),\n",
        "\n",
        "            layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    # âœ… Build the model\n",
        "    model = create_simple_effective_cnn(len(class_names))\n",
        "\n",
        "    # âœ… Compile the model\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.001,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-7\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nY8Ml0Jy1sX",
        "outputId": "333c9993-ae7c-472d-d3ca-01ea184ca6f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3 - Compiling and Training the CNN**"
      ],
      "metadata": {
        "id": "F67nJPlKzTVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"âœ… Simple & Effective CNN created successfully\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nGCgaA_YzW2v",
        "outputId": "9757663d-5de2-458e-f47f-6e811a6df4a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Simple & Effective CNN created successfully\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚           \u001b[38;5;34m896\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequential (\u001b[38;5;33mSequential\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation (\u001b[38;5;33mActivation\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚       \u001b[38;5;34m295,168\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚    \u001b[38;5;34m25,690,624\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m131,328\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              â”‚         \u001b[38;5;34m1,028\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,624</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,216,388\u001b[0m (100.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,216,388</span> (100.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,213,892\u001b[0m (100.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,213,892</span> (100.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,496\u001b[0m (9.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> (9.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# Part 3 - Conservative Training Strategy\n",
        "# -----------------------------------------\n",
        "\n",
        "# âœ… Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=25,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.8,\n",
        "    patience=15,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_simple_cnn.keras',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# âœ… Train the model\n",
        "print(\"ğŸš€ Training Simple & Effective CNN...\")\n",
        "epochs = 150  # More epochs with early stopping\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# âœ… Load best model\n",
        "model.load_weights('best_simple_cnn.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlhNk0AEy4b6",
        "outputId": "17b0231a-0e73-43fb-9778-0dacb9b998a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Training Simple & Effective CNN...\n",
            "Epoch 1/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.3943 - loss: 1.6239\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31111, saving model to best_simple_cnn.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.3958 - loss: 1.6214 - val_accuracy: 0.3111 - val_loss: 1.8166 - learning_rate: 0.0010\n",
            "Epoch 2/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.5672 - loss: 1.3054\n",
            "Epoch 2: val_accuracy improved from 0.31111 to 0.42222, saving model to best_simple_cnn.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 236ms/step - accuracy: 0.5680 - loss: 1.3040 - val_accuracy: 0.4222 - val_loss: 1.8500 - learning_rate: 0.0010\n",
            "Epoch 3/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.6701 - loss: 1.0930\n",
            "Epoch 3: val_accuracy did not improve from 0.42222\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.6702 - loss: 1.0927 - val_accuracy: 0.2500 - val_loss: 1.9919 - learning_rate: 0.0010\n",
            "Epoch 4/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7200 - loss: 0.9681\n",
            "Epoch 4: val_accuracy did not improve from 0.42222\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.7203 - loss: 0.9678 - val_accuracy: 0.2889 - val_loss: 2.1730 - learning_rate: 0.0010\n",
            "Epoch 5/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7853 - loss: 0.8492\n",
            "Epoch 5: val_accuracy did not improve from 0.42222\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.7855 - loss: 0.8491 - val_accuracy: 0.3222 - val_loss: 2.2199 - learning_rate: 0.0010\n",
            "Epoch 6/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.8126 - loss: 0.7707\n",
            "Epoch 6: val_accuracy improved from 0.42222 to 0.58889, saving model to best_simple_cnn.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 305ms/step - accuracy: 0.8126 - loss: 0.7706 - val_accuracy: 0.5889 - val_loss: 1.2876 - learning_rate: 0.0010\n",
            "Epoch 7/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8492 - loss: 0.7117\n",
            "Epoch 7: val_accuracy improved from 0.58889 to 0.70000, saving model to best_simple_cnn.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 239ms/step - accuracy: 0.8491 - loss: 0.7119 - val_accuracy: 0.7000 - val_loss: 1.1298 - learning_rate: 0.0010\n",
            "Epoch 8/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8891 - loss: 0.6312\n",
            "Epoch 8: val_accuracy improved from 0.70000 to 0.72778, saving model to best_simple_cnn.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 347ms/step - accuracy: 0.8889 - loss: 0.6317 - val_accuracy: 0.7278 - val_loss: 1.0768 - learning_rate: 0.0010\n",
            "Epoch 9/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8946 - loss: 0.6114\n",
            "Epoch 9: val_accuracy did not improve from 0.72778\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 205ms/step - accuracy: 0.8946 - loss: 0.6116 - val_accuracy: 0.6389 - val_loss: 1.2183 - learning_rate: 0.0010\n",
            "Epoch 10/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9125 - loss: 0.5833\n",
            "Epoch 10: val_accuracy did not improve from 0.72778\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9125 - loss: 0.5834 - val_accuracy: 0.6889 - val_loss: 1.1986 - learning_rate: 0.0010\n",
            "Epoch 11/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9221 - loss: 0.5443\n",
            "Epoch 11: val_accuracy improved from 0.72778 to 0.76667, saving model to best_simple_cnn.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 248ms/step - accuracy: 0.9222 - loss: 0.5442 - val_accuracy: 0.7667 - val_loss: 0.9202 - learning_rate: 0.0010\n",
            "Epoch 12/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9353 - loss: 0.5116\n",
            "Epoch 12: val_accuracy improved from 0.76667 to 0.84444, saving model to best_simple_cnn.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 0.9354 - loss: 0.5114 - val_accuracy: 0.8444 - val_loss: 0.8254 - learning_rate: 0.0010\n",
            "Epoch 13/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9556 - loss: 0.4752\n",
            "Epoch 13: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 205ms/step - accuracy: 0.9555 - loss: 0.4753 - val_accuracy: 0.8056 - val_loss: 0.9331 - learning_rate: 0.0010\n",
            "Epoch 14/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9363 - loss: 0.5123\n",
            "Epoch 14: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - accuracy: 0.9362 - loss: 0.5125 - val_accuracy: 0.7500 - val_loss: 1.0805 - learning_rate: 0.0010\n",
            "Epoch 15/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9514 - loss: 0.4791\n",
            "Epoch 15: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.9514 - loss: 0.4792 - val_accuracy: 0.7389 - val_loss: 1.0367 - learning_rate: 0.0010\n",
            "Epoch 16/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9445 - loss: 0.4721\n",
            "Epoch 16: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.9444 - loss: 0.4723 - val_accuracy: 0.6722 - val_loss: 1.6170 - learning_rate: 0.0010\n",
            "Epoch 17/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9527 - loss: 0.4681\n",
            "Epoch 17: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - accuracy: 0.9526 - loss: 0.4683 - val_accuracy: 0.7389 - val_loss: 1.1798 - learning_rate: 0.0010\n",
            "Epoch 18/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9491 - loss: 0.4942\n",
            "Epoch 18: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.9490 - loss: 0.4945 - val_accuracy: 0.7889 - val_loss: 1.0550 - learning_rate: 0.0010\n",
            "Epoch 19/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9606 - loss: 0.4929\n",
            "Epoch 19: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9605 - loss: 0.4931 - val_accuracy: 0.7556 - val_loss: 1.2869 - learning_rate: 0.0010\n",
            "Epoch 20/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9436 - loss: 0.5119\n",
            "Epoch 20: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - accuracy: 0.9437 - loss: 0.5118 - val_accuracy: 0.7500 - val_loss: 1.2320 - learning_rate: 0.0010\n",
            "Epoch 21/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9457 - loss: 0.5180\n",
            "Epoch 21: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.9457 - loss: 0.5180 - val_accuracy: 0.8222 - val_loss: 1.0761 - learning_rate: 0.0010\n",
            "Epoch 22/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9596 - loss: 0.4924\n",
            "Epoch 22: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9596 - loss: 0.4924 - val_accuracy: 0.8167 - val_loss: 0.9885 - learning_rate: 0.0010\n",
            "Epoch 23/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9598 - loss: 0.4868\n",
            "Epoch 23: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9598 - loss: 0.4867 - val_accuracy: 0.7833 - val_loss: 1.1340 - learning_rate: 0.0010\n",
            "Epoch 24/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9636 - loss: 0.4712\n",
            "Epoch 24: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9636 - loss: 0.4713 - val_accuracy: 0.7222 - val_loss: 1.4465 - learning_rate: 0.0010\n",
            "Epoch 25/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9559 - loss: 0.4973\n",
            "Epoch 25: val_accuracy did not improve from 0.84444\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9560 - loss: 0.4973 - val_accuracy: 0.7222 - val_loss: 1.1773 - learning_rate: 0.0010\n",
            "Epoch 26/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9706 - loss: 0.4773\n",
            "Epoch 26: val_accuracy improved from 0.84444 to 0.85556, saving model to best_simple_cnn.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 248ms/step - accuracy: 0.9706 - loss: 0.4770 - val_accuracy: 0.8556 - val_loss: 0.9925 - learning_rate: 0.0010\n",
            "Epoch 27/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9598 - loss: 0.4676\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 205ms/step - accuracy: 0.9598 - loss: 0.4679 - val_accuracy: 0.8167 - val_loss: 0.9463 - learning_rate: 0.0010\n",
            "Epoch 28/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9701 - loss: 0.4570\n",
            "Epoch 28: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9702 - loss: 0.4568 - val_accuracy: 0.8167 - val_loss: 1.0269 - learning_rate: 8.0000e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9712 - loss: 0.4510\n",
            "Epoch 29: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - accuracy: 0.9711 - loss: 0.4509 - val_accuracy: 0.8056 - val_loss: 1.0509 - learning_rate: 8.0000e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9835 - loss: 0.4122\n",
            "Epoch 30: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9834 - loss: 0.4122 - val_accuracy: 0.8111 - val_loss: 0.9318 - learning_rate: 8.0000e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9908 - loss: 0.3791\n",
            "Epoch 31: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.9908 - loss: 0.3791 - val_accuracy: 0.8222 - val_loss: 0.9078 - learning_rate: 8.0000e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9854 - loss: 0.3663\n",
            "Epoch 32: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - accuracy: 0.9853 - loss: 0.3664 - val_accuracy: 0.8111 - val_loss: 1.0597 - learning_rate: 8.0000e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9782 - loss: 0.3769\n",
            "Epoch 33: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9782 - loss: 0.3770 - val_accuracy: 0.7778 - val_loss: 0.9250 - learning_rate: 8.0000e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9686 - loss: 0.4030\n",
            "Epoch 34: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9687 - loss: 0.4031 - val_accuracy: 0.7833 - val_loss: 1.2358 - learning_rate: 8.0000e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9765 - loss: 0.3923\n",
            "Epoch 35: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - accuracy: 0.9765 - loss: 0.3924 - val_accuracy: 0.8222 - val_loss: 0.9917 - learning_rate: 8.0000e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9741 - loss: 0.3921\n",
            "Epoch 36: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9740 - loss: 0.3925 - val_accuracy: 0.7389 - val_loss: 1.4142 - learning_rate: 8.0000e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9712 - loss: 0.4265\n",
            "Epoch 37: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9711 - loss: 0.4267 - val_accuracy: 0.8222 - val_loss: 1.0279 - learning_rate: 8.0000e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9658 - loss: 0.4611\n",
            "Epoch 38: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - accuracy: 0.9658 - loss: 0.4608 - val_accuracy: 0.8056 - val_loss: 1.0033 - learning_rate: 8.0000e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9795 - loss: 0.4253\n",
            "Epoch 39: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9794 - loss: 0.4254 - val_accuracy: 0.7889 - val_loss: 1.2030 - learning_rate: 8.0000e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9776 - loss: 0.4207\n",
            "Epoch 40: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.9775 - loss: 0.4209 - val_accuracy: 0.8444 - val_loss: 0.9930 - learning_rate: 8.0000e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9703 - loss: 0.4615\n",
            "Epoch 41: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - accuracy: 0.9703 - loss: 0.4613 - val_accuracy: 0.7944 - val_loss: 1.2871 - learning_rate: 8.0000e-04\n",
            "Epoch 42/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9718 - loss: 0.4238\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9717 - loss: 0.4240 - val_accuracy: 0.7722 - val_loss: 1.1918 - learning_rate: 8.0000e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9729 - loss: 0.4264\n",
            "Epoch 43: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9729 - loss: 0.4263 - val_accuracy: 0.8389 - val_loss: 0.9557 - learning_rate: 6.4000e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9794 - loss: 0.3989\n",
            "Epoch 44: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.9795 - loss: 0.3988 - val_accuracy: 0.8444 - val_loss: 0.9359 - learning_rate: 6.4000e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9935 - loss: 0.3613\n",
            "Epoch 45: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9934 - loss: 0.3612 - val_accuracy: 0.8000 - val_loss: 1.0889 - learning_rate: 6.4000e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9834 - loss: 0.3618\n",
            "Epoch 46: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.9834 - loss: 0.3617 - val_accuracy: 0.8500 - val_loss: 0.8890 - learning_rate: 6.4000e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9852 - loss: 0.3479\n",
            "Epoch 47: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9853 - loss: 0.3478 - val_accuracy: 0.8056 - val_loss: 1.1078 - learning_rate: 6.4000e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9918 - loss: 0.3268\n",
            "Epoch 48: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.9918 - loss: 0.3268 - val_accuracy: 0.7389 - val_loss: 1.4410 - learning_rate: 6.4000e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9837 - loss: 0.3367\n",
            "Epoch 49: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.9838 - loss: 0.3365 - val_accuracy: 0.8222 - val_loss: 0.8225 - learning_rate: 6.4000e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9945 - loss: 0.3033\n",
            "Epoch 50: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.9945 - loss: 0.3034 - val_accuracy: 0.8222 - val_loss: 0.9383 - learning_rate: 6.4000e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9879 - loss: 0.3057\n",
            "Epoch 51: val_accuracy did not improve from 0.85556\n",
            "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.9878 - loss: 0.3058 - val_accuracy: 0.8167 - val_loss: 1.0442 - learning_rate: 6.4000e-04\n",
            "Epoch 51: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Save full model after training (only needs to be done once)\n",
        "model.save(\"/content/drive/MyDrive/fighter_jet_model.keras\")\n",
        "print(\"âœ… Model saved to Google Drive.\")\n"
      ],
      "metadata": {
        "id": "7s-2-XDJBpDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ“ˆ Part 4 - Evaluate Model**"
      ],
      "metadata": {
        "id": "eHtGBta7_I-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# Part 4 - Evaluation\n",
        "# -----------------------------------------\n",
        "\n",
        "# âœ… Evaluate\n",
        "val_loss, val_acc = model.evaluate(val_ds, verbose=0)\n",
        "print(f\"\\nğŸ”¥ Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# âœ… Detailed predictions\n",
        "y_pred_probs = model.predict(val_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.concatenate([y for _, y in val_ds], axis=0)\n",
        "\n",
        "# âœ… Calculate metrics\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
        "    y_true, y_pred, average='weighted'\n",
        ")\n",
        "\n",
        "print(f\"âœ… Precision: {precision:.4f}\")\n",
        "print(f\"âœ… Recall: {recall:.4f}\")\n",
        "print(f\"âœ… F1-Score: {f1_score:.4f}\")\n",
        "\n",
        "# âœ… Classification Report\n",
        "print(\"\\nğŸ“Š Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# âœ… Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    conf_matrix.astype(\"float\") / conf_matrix.sum(axis=1)[:, np.newaxis],\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap='Blues',\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Normalized Confusion Matrix - Simple & Effective CNN\")\n",
        "plt.show()\n",
        "\n",
        "# âœ… Training History Visualization\n",
        "# plt.figure(figsize=(10, 5))\n",
        "\n",
        "# # Accuracy\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
        "# plt.plot(history.history['val_accuracy'], label='Val Accuracy', color='red')\n",
        "# plt.title(\"Accuracy Over Epochs\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# # plt.legend()\n",
        "\n",
        "# # Loss\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
        "# plt.plot(history.history['val_loss'], label='Val Loss', color='red')\n",
        "# plt.title(\"Loss Over Epochs\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# # plt.legend()\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k-zdhjUWy8GW",
        "outputId": "ba8d9f5c-3b22-4a4e-8433-6db8f3a86771"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¥ Validation Accuracy: 0.8556\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "âœ… Precision: 0.8670\n",
            "âœ… Recall: 0.8556\n",
            "âœ… F1-Score: 0.8558\n",
            "\n",
            "ğŸ“Š Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        AH64       0.75      0.98      0.85        44\n",
            "          B1       0.91      0.78      0.84        51\n",
            "          B2       0.85      0.81      0.83        43\n",
            "          E2       0.95      0.86      0.90        42\n",
            "\n",
            "    accuracy                           0.86       180\n",
            "   macro avg       0.87      0.86      0.86       180\n",
            "weighted avg       0.87      0.86      0.86       180\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ–¼ï¸ Part 5 - Gradio Interface**"
      ],
      "metadata": {
        "id": "z1IdEOJr_dyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Install Gradio\n",
        "!pip install gradio --quiet\n",
        "\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# âœ… Prediction Function\n",
        "def classify_jet(image):\n",
        "    image = image.resize(img_size)\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    img_array = tf.expand_dims(img_array, axis=0) / 255.0\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_idx = np.argmax(predictions)\n",
        "    predicted_label = class_names[predicted_idx]\n",
        "    confidence = predictions[0][predicted_idx]\n",
        "    return f\"ğŸš€ Predicted: {predicted_label} ({confidence*100:.2f}% confidence)\"\n",
        "\n",
        "# âœ… Launch Gradio Interface\n",
        "jet_classifier = gr.Interface(\n",
        "    fn=classify_jet,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Fighter Jet Classifier\",\n",
        "    description=\"Upload an image of a fighter jet and get the predicted class using CNN\"\n",
        ")\n",
        "\n",
        "jet_classifier.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "_n-OSUYUyZmH",
        "outputId": "268c8ece-7576-4923-b31b-78a79ee7b641"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://568d0c1ae74c5cd40b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://568d0c1ae74c5cd40b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://568d0c1ae74c5cd40b.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}